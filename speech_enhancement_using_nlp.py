# -*- coding: utf-8 -*-
"""SPEECH_ENHANCEMENT_USING_NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uV_t8QvSilyAbyK9DktBpkriVZlGI703

## INSTALLATION
"""

pip install PYPDF2

pip install pipwin

pip install pyttsx3

pip install SpeechRecognition

pip install SpeechRecognition pydub

pip install pyaudio

pip install pyaudio

pip install nlp

pip install torch

pip install fasttext

pip install transformers

import nltk
nltk.download('punkt')

"""#converting_to_wav & TXT_FILE"""

# all imports
from IPython.display import Javascript
from google.colab import output
from base64 import b64decode
from io import BytesIO
!pip -q install pydub
from pydub import AudioSegment

RECORD = """
const sleep  = time => new Promise(resolve => setTimeout(resolve, time))
const b2text = blob => new Promise(resolve => {
  const reader = new FileReader()
  reader.onloadend = e => resolve(e.srcElement.result)
  reader.readAsDataURL(blob)
})

var record = time => new Promise(async resolve => {
  stream = await navigator.mediaDevices.getUserMedia({ audio: true })
  recorder = new MediaRecorder(stream)
  chunks = []
  recorder.ondataavailable = e => chunks.push(e.data)
  recorder.start()
  await sleep(time)
  recorder.onstop = async ()=>{
    blob = new Blob(chunks)
    text = await b2text(blob)
    resolve(text)
  }
  recorder.stop()
})
"""

def record(sec=3):
  display(Javascript(RECORD))
  s = output.eval_js('record(%d)' % (sec*1000))
  b = b64decode(s.split(',')[1])
  audio = AudioSegment.from_file(BytesIO(b))
  return audio

import IPython.display as ipd
from IPython.display import Audio, display
from IPython.display import HTML

import subprocess
subprocess.call(['ffmpeg', '-i','/content/audio.m4a','converted_audio3.wav'])

ipd.Audio('converted_audio3.wav')

from PyPDF2 import PdfReader

def pdf_to_txt(input_path, output_path):
    with open(input_path, 'rb') as file:
        pdf = PdfReader(file)
        text = ''
        for page in pdf.pages:
            text += page.extract_text()

    with open(output_path, 'w', encoding='utf-8') as file:
        file.write(text)

# Usage example
pdf_to_txt('/content/txt_file.pdf', '/content/txt_file.txt')

"""#audio_to_text"""

# importing libraries
import speech_recognition as sr
import os
from pydub import AudioSegment
from pydub.silence import split_on_silence

# create a speech recognition object
r = sr.Recognizer()

# a function that splits the audio file into chunks
# and applies speech recognition
def get_large_audio_transcription(path):
    """
    Splitting the large audio file into chunks
    and apply speech recognition on each of these chunks
    """
    # open the audio file using pydub
    sound = AudioSegment.from_wav(path)
    # split audio sound where silence is 700 miliseconds or more and get chunks
    chunks = split_on_silence(sound,
        # experiment with this value for your target audio file
        min_silence_len = 1000,
        # adjust this per requirement
        silence_thresh = sound.dBFS-16,
        # keep the silence for 1 second, adjustable as well
        keep_silence=500,
    )
    folder_name = "audio-chunks"
    # create a directory to store the audio chunks
    if not os.path.isdir(folder_name):
        os.mkdir(folder_name)
    whole_text = ""
    # process each chunk
    for i, audio_chunk in enumerate(chunks, start=1):
        # export audio chunk and save it in
        # the `folder_name` directory.
        chunk_filename = os.path.join(folder_name, f"chunk{i}.wav")
        audio_chunk.export(chunk_filename, format="wav")
        # recognize the chunk
        with sr.AudioFile(chunk_filename) as source:
            audio_listened = r.record(source)
            # try converting it to text
            try:
                text = r.recognize_google(audio_listened)
            except sr.UnknownValueError as e:
                print("Error:", str(e))
            else:
                text = f"{text.capitalize()}. "
                print(chunk_filename, ":", text)
                whole_text += text
    # return the text for all chunks detected
    return whole_text

path = '/content/converted_audio3.wav'
print("\nFull text:", get_large_audio_transcription(path))

file = open("speech_to_text.txt","w+")
file.write(get_large_audio_transcription(path))
file.close()

def convert_file_to_single_line(input_path, output_path):
    with open(input_path, 'r') as file:
        content = file.read()

    single_line_content = content.replace('\n', ' ')

    with open(output_path, 'w') as file:
        file.write(single_line_content)

# Example usage
input_file_path = '/content/txt_file.txt'
output_file_path = '/content/txt_file1.txt'
convert_file_to_single_line(input_file_path, output_file_path)

import numpy as np
data = np.loadtxt("/content/txt_file1.txt",dtype='str')
string="".join(data)

#printing  words by line by line from original text file-

# array from text file
data1 = np.loadtxt("/content/speech_to_text.txt", dtype='str')
string1=" ".join(data1)

print(string)

print(string1)

"""## Removing Punctuations"""

import re



op_string = re.sub(r'[^\w\s]','',string)

"""#similarities checking"""

from transformers import BertTokenizer, BertModel
import torch
import numpy as np

def calculate_similarity(text1, text2):
    # Load BERT model and tokenizer
    tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
    model = BertModel.from_pretrained("bert-base-uncased")

    # Tokenize and encode the text
    inputs = tokenizer([text1, text2], return_tensors="pt", padding=True, truncation=True)
    outputs = model(**inputs)

    # Extract the embeddings for the [CLS] token
    embeddings = outputs.last_hidden_state[:, 0, :]

    # Calculate cosine similarity between embeddings
    similarity_score = np.dot(embeddings[0].detach().numpy(), embeddings[1].detach().numpy()) / (
        np.linalg.norm(embeddings[0].detach().numpy()) * np.linalg.norm(embeddings[1].detach().numpy())
    )

    return similarity_score

# Example usage
a=op_string
b=string1

similarity = calculate_similarity(a, b)
print(f"Similarity: {similarity}")